{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GTA Lab 3: Python and PostgreSQL - Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiona\n",
    "from shapely.geometry import LineString\n",
    "import psycopg2\n",
    "from psycopg2.extensions import AsIs\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shpfile=fiona.open(\"swissTLM3D_TLM_EISENBAHN.shp\",\"r\")\n",
    "print(shpfile.schema)\n",
    "len(list(shpfile))\n",
    "print(len(shpfile[28]))\n",
    "print(shpfile[345])\n",
    "print(shpfile[345][\"geometry\"][\"coordinates\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shxfile=fiona.open(\"swissTLM3D_TLM_EISENBAHN.shx\",\"r\")\n",
    "print(shxfile.schema)\n",
    "#ich glaub das ist genau das gleiche, also enthÃ¤lt die gleichen Informationen aber vielleicht in einem anderen Format==> shp/shx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Connecting with the database:\n",
    "import numpy as np\n",
    "\n",
    "structure=(list(shpfile))\n",
    "print(structure)\n",
    "db_gta = {\"dbname\": \"gta\",\n",
    "          \"port\": \"5432\",\n",
    "          \"user\": \"gta_p4\",\n",
    "          \"password\": \"***REMOVED***\",\n",
    "          \"host\": \"ikgpgis.ethz.ch\"}\n",
    "conn = psycopg2.connect(**db_gta)\n",
    "cur=conn.cursor()\n",
    "for i in range(len(list(shpfile))):\n",
    "    line = LineString(np.array(structure[i]['geometry']['coordinates'])[:,:2])\n",
    "    #print(np.array((structure[i]['geometry']['coordinates']))[:][0:2])\n",
    "    #print(line)\n",
    "\n",
    "    cur.execute(f\"INSERT INTO train_tracks (geom) VALUES ('{line}');\")\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample=np.array([(2696490.9499999993, 1261351.914999999, 438.5939999999973), (2696504.1799999997, 1261368.3150000013, 438.5939999999973), (2696511.1000000015, 1261377.484000001, 438.5939999999973)])\n",
    "print(sample)\n",
    "line = LineString(sample[:,0:2])\n",
    "print(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction:\n",
    "\n",
    "Today we aim to transfer data from two different data sources into a common database. Both datasets describe artworks in Zurich city (e.g. a statue). The data is provided in two .csv files.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules\n",
    "\n",
    "In the beginning of a Python scripts we import the libraries that are required for executing the script. Libraries provide Python code that was written by other people to solve a specific problem. If you have a task in Python, it is always worth researching for existing modules, since there are many well-documented open source packages available, e.g. in the Python Package Index (PyPI). \n",
    "\n",
    "Today we will mainly use the package **psycopg2**. This library provides functionality to communicate in Python with a Postgresql database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from psycopg2.extensions import AsIs\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Working with Pandas and csv files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General information about csv files\n",
    "\n",
    "CSV is one of the most common formats to save tabular data. CSV files have a fixed number of columns and each element in a column is separated from the next element with a certain separator, e.g. a comma. However, a practical challenge in working with csv files is the missing standard of their format: Different separators may be used (comma, semicolon, etc) or different encodings are user (e.g. ASCII or UTF-8). The format must therefore be defined by the user when reading and writing CSV files.\n",
    "\n",
    "#### Identifying csv parameters\n",
    "\n",
    "In order to identify these parameters, you can for example open the csv file in a simple text editor and visually identify the used separators. To do so, it is important to use an editor that shows the file in its most raw format (for example NOT excel, because it would already render the file and not show the raw text). On Windows you can for example use Notepad or Notepad++, on Mac you can use TextEdit. \n",
    "\n",
    "#### Reading csv files with Python\n",
    "\n",
    "In order to load the csv data and to write it to a PostgeSQL database, you first need to read the csv file. You can use the pandas function **pd.read_csv**. The function takes a file path as input and all further optional parameters are used to read the file in the correct format. You call find the documentation with all parameters here: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html. \n",
    "\n",
    "Important parameters are the following:\n",
    "\n",
    "  + **sep**: The separator used in the csv for separating columns\n",
    "  + **thousands**: Separator for thousands, e.g. 1.000 or 1,000 \n",
    "  + **decimal**: Separator for decimals (default is a dot)\n",
    "  + **encoding**: Encoding of the csv file. It is one of the most common error sources when reading csv files. **Here are some popular endocings that can be tested:**: 'latin-1', 'utf-8', 'iso-8859-1', 'utf_8_sig' or 'cp1252'\n",
    "\n",
    "Example:\n",
    "```python\n",
    "data = pd.read_csv(path_csv, sep=\",\", decimal=\",\") \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.1: Reading csv files\n",
    "\n",
    "Load the files **kunstimstadtraum_source1.csv** and **kunstimstadtraum_source2.csv** which you can find in the `data` folder. \n",
    "- First open the data in a text editor and check the formatting. Which separator is used?\n",
    "- Use the function pd.read_csv as described above and set the parameters correctly. Which encoding is used? Do you have an idea why UTF-8 is not used?\n",
    "- Check the correctness by printing the first few rows of the table with the function **df.head()** (if df is your Pandas dataframe) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read kunstimstadtraum_source1.csv\n",
    "source1 = pd.read_csv(\"data/kunstimstadtraum_source1.csv\", encoding = \"latin-1\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if everything was read correctly\n",
    "source1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read kunstimstadtraum_source2.csv\n",
    "source2 = pd.read_csv(\"data/kunstimstadtraum_source2.csv\", encoding = \"latin-1\", delimiter=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if everything was read correctly\n",
    "source2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2: Working with Pandas:\n",
    "\n",
    "For selecting and manipulating data you can use SQL, if the data is already available in a database. On the other hand, data can also be manipulated directly in Python. For more complex processing, for connecting with other data, data processing in Python is very important. We therefore practice data selection and manipulation with Pandas in this lab. \n",
    "\n",
    "Pandas represents tables in so-called DataFrames. The DataFrame class implements many methods for table operations, such as selection, sorting, grouping or joining.\n",
    "\n",
    "Selecting single columns is done with a syntax similar to a dictionary:\n",
    "\n",
    "```python\n",
    "source1[\"GATTUNG\"]\n",
    "\n",
    "0      Freiplastik\n",
    "1      Freiplastik\n",
    "2          Brunnen\n",
    "3          Brunnen\n",
    "4      Freiplastik\n",
    "          ...     \n",
    "189     Gestaltung\n",
    "190    Freiplastik\n",
    "191    Freiplastik\n",
    "192     Bauplastik\n",
    "193        Brunnen\n",
    "Name: GATTUNG, Length: 194, dtype: object\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.2.1: Sort the artworks in table `source1` alphabetically by the first name of the artist.\n",
    "\n",
    "To do so, check out the documentation of the function sort_values: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sort_values.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: sort values\n",
    "df_sorted = source1.sort_values(by=\"KUENSTLER\")\n",
    "df_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2.2: Selection\n",
    "\n",
    "Create a new table `df_filtered`, that should only contain artworks of type (Gattung) \"Brunnen\". \n",
    "\n",
    "Tip: As shown in the lab slides, we can filter with boolean indices. The Syntax is \n",
    "\n",
    "```\n",
    "df_filtered = df[df[column_name] == value]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: filter for Gattung Brunnen\n",
    "df_filtered = source1[source1[\"GATTUNG\"]==\"Brunnen\"]\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.3:  Iterating over dataframes\n",
    "\n",
    "In exercise 3 we will insert all rows into the database individually. As a preparation, we want to use a pandas function to iterate over the rows of a DataFrame, namely `df.iterrows()`. This function is a *generator*, which means that you can access the elements with a for-loop. In each iteration (for each row), we can again select a column as above. This yields a single value of one particular table cell. **Print the artist (KUENSTLER) of the first five rows sequentially in a for loop:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: print rows with iterrows\n",
    "for i, row in source1.iterrows():\n",
    "    print(row[\"KUENSTLER\"])\n",
    "    if i>4:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PostgreSQL and psycopg2\n",
    "\n",
    "We now want to operate on a PostgreSQL database (with PostGIS extension) with Python. This enables you to keep large amounts of data in a database, while making use of the rich functionality of Python for preprocessing and analysis. We use the library **psycopg2** for communicating with the database.\n",
    "\n",
    "#### Accessing a database with psycopg2\n",
    "\n",
    "In order to connect to a database, you require several information about the database, such as database name, user name, password, port, host. These variables usually stay the same, so it makes sense to save them in variables in the beginning. \n",
    "\n",
    "To conntect to a database, you can use the **connect** method, which returns a **connection** object. The syntax is the following: \n",
    "\n",
    "```python\n",
    "conn = psycopg2.connect(dbname=my_dbname, port=my_port, user=my_user, password=my_password, host=my_host)\n",
    "```\n",
    "\n",
    "**Tip:** The syntax later can be simplified significantly if we store the information in a Python dictionary and use the [*kwargs* syntax](https://realpython.com/python-kwargs-and-args/):\n",
    "```python\n",
    "db_credentials = {\"dbname\": NAME,\n",
    "                  \"port\": PORTNUMMER,\n",
    "                  \"user\": BENUTZERNAME,\n",
    "                  \"password\": PASSWORT,\n",
    "                  \"host\": HOSTNUMMER}\n",
    "conn = psycopg2.connect(**db_credentials)\n",
    "```\n",
    "\n",
    "#### Connection and Cursor objekts\n",
    "\n",
    "The variable `conn` is now an object that maintains and administers the connection to your database. To interact with the database now, you require a cursor. A cursor is created with the command\n",
    "```\n",
    "conn.cursor()\n",
    "```\n",
    "\n",
    "In today's lab you will mainly use the following cursor methods:\n",
    "\n",
    "+ **cur.execute(\"sql string\")**: Executes any sql query on your database.\n",
    "+ **conn.commit()**: Submits the changes to your database (such that it is permanently modified).\n",
    "+ **conn.rollback()**: Reverts non-permanent changes. This is in particular necessary if you have commited an invalid SQL request. You first have to revert it with conn.rollback() before continuing in that case.\n",
    "+ **conn.close()**: Closes the connection\n",
    "\n",
    "Here is a typical sequence of commands for a database request:\n",
    "\n",
    "```python\n",
    "conn = psycopg2.connect(**db_credentials)\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"your_sql_query\")\n",
    "conn.commit()\n",
    "conn.close()\n",
    "```\n",
    "\n",
    "For further information on psycopg, see http://initd.org/psycopg/docs/usage.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Creating a new table with psycopg2\n",
    "\n",
    "### Preliminaries:\n",
    "+ schema name gtaXX (your schema)\n",
    "+ table name: kunst_im_stadtraum\n",
    "+ the table should have the following fields:\n",
    "\n",
    "|field name | datatyp|\n",
    "|-----------|---------|\n",
    "|id         | SERIAL PRIMARY KEY|\n",
    "|titel      | VARCHAR|\n",
    "|kuenstler  | VARCHAR|\n",
    "|standort   | VARCHAR|\n",
    "|lon        | FLOAT|\n",
    "|lat        | FLOAT|\n",
    "|geometry   | POINT|\n",
    "\n",
    "### Procedure:\n",
    "\n",
    "1. Save the information of your database connection (host, username, etc, see above) in a dictionary\n",
    "2. Connect to the database\n",
    "3. Initialize the cursor\n",
    "4. Create a SQL command as a Python string, where you use the CREATE TABLE statement in order to create a table with all fields **except for the geomety** (we will deal with the geometry later). In order to **create a table inside your schema** (e.g. gta23_01), write the table name with the following syntax: `schema_name.table_name` (e.g. gta23_01.kunst_im_stadtraum_01).\n",
    "\n",
    "Syntax of **CREATE TABLE** statement:\n",
    "```SQL\n",
    "CREATE TABLE IF NOT EXISTS schema_name.table_name(\n",
    "column1 datatype, column2 datatype, ...., columnX datatype);\n",
    "```\n",
    "5. Execute the SQL query\n",
    "6. Add the Geometry column with a new SQL query. \n",
    "\n",
    "Syntax of **AddGeometryColumn** statement (see documentation http://postgis.net/docs/AddGeometryColumn.html):\n",
    "```SQL\n",
    "SELECT AddGeometryColumn(varchar schema_name, varchar table_name, \n",
    "varchar column_name, integer SRID, varchar geom_type, integer dimension)\n",
    "```\n",
    "\n",
    "7. Validate the changes with the commit command\n",
    "8. Close the database connection\n",
    "\n",
    "### Tips: \n",
    "+ Write the commands in separate cells. This simplifies debugging.\n",
    "+ If you have sent an invalid request to the database, you have to reset the connection object. There are two possibilities to do so:\n",
    "    + Reset the erronous command with ```conn.rollback()```\n",
    "    + Connect again from scratch (```conn = psycopg2.connect(**db_credentials)```)\n",
    "+ **Important:** The varchar arguments have to be passed as a string in the SQL query. However, since the whole SQL request is a String itself, we have to use a String inside a String, i.e.: \"some outer string 'some inner string'\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps 1-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "db_credentials = {\n",
    "    \"user\": \"gta_tutor\",\n",
    "    \"password\": \"gta_pw\",\n",
    "    \"host\": \"ikgpgis.ethz.ch\",\n",
    "    \"port\": \"5432\",\n",
    "    \"dbname\": \"gta\"\n",
    "}\n",
    "\n",
    "# establish database connection\n",
    "conn = psycopg2.connect(**db_credentials)\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: query string\n",
    "create_table_query = \"CREATE TABLE IF NOT EXISTS gta_tutor.kunst_im_stadtraum\\\n",
    "(id SERIAL PRIMARY KEY, titel VARCHAR, kuenstler VARCHAR, standort VARCHAR, lon FLOAT, lat FLOAT)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: execute\n",
    "cur.execute(create_table_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add geometry\n",
    "add_geom_query = \"SELECT AddGeometryColumn('gta_tutor', 'kunst_im_stadtraum', 'geometry', 4326, 'POINT', 2)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: execute\n",
    "cur.execute(add_geom_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8 - 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: finalize and close connection\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check in PgAdmin whether your table was created correctly!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3: Import data\n",
    "\n",
    "## Exercise 3.1: Importing the first csv file\n",
    "\n",
    "Fill the fields of your newly created table with the rows of the first csv file (\"data/kunstimstadtraum_source1.csv\" / source1), with the following steps:\n",
    "\n",
    "1. Create a database connection and a cursor\n",
    "2. Check that your input data looks correct by printing `source1.head()`\n",
    "3. Use the method `cur.mogrify` to test a String with varying content. cur.mogrify() provides you the string which would then be sent to the database with cur.execute. Check the psycopg2 syntax here: [https://www.psycopg.org/docs/usage.html](https://www.psycopg.org/docs/usage.html)\n",
    "4. Iterate over the `source` DataFrame with a for-loop\n",
    "5. In each iteration, set suitable variables with the necessary values of the table row. For example, we need the value for column `KUENSTLER` in order to fill the varchar field `kuenstler` of the table in our database, so we can save it in a variable `kuenstler = row[\"KUENSTLER\"]` as an intermediate step. **Import the WGS representation of latitude and longitude**!\n",
    "6. Execute a SQL-INSERT statement with cur.execute, where the variables of step 5 are used in the SQL query string. Syntax of **INSERT** statement:\n",
    "\n",
    "```SQL\n",
    "INSERT INTO schema_name.table_name (column1, column2, column3, ...)\n",
    "VALUES (value1, value2, value3, ...); \n",
    "```\n",
    "\n",
    "7. Validate your changes with the commit command and close the database connection.\n",
    "8. Test your your result with the function **count_items**, which counts the number of rows in your table in the PostgreSQL database. After reading the first .csv file, there should be 194 rows.\n",
    "\n",
    "### Important: Do NOT fill the geom-column at this point! We will add the geometry with PostGIS in exercise 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: establish database connection\n",
    "conn = psycopg2.connect(**db_credentials)\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: check source1 table\n",
    "source1[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3\n",
    "\n",
    "Example for using placeholders in a String:\n",
    "\n",
    "cur.mogrify(\"INSERT INTO test (num, data) VALUES (%s, %s)\",(100, \"abc'def\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the example from above:\n",
    "sql_string_with_placeholders = \"INSERT INTO test (num, data) VALUES (%s, %s)\"\n",
    "cur.mogrify(sql_string_with_placeholders,(100, \"abc'def\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 - 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop all rows from csv1\n",
    "for idx, row in source1.iterrows():\n",
    "    \n",
    "    #prepate list of input values\n",
    "    titel = row[\"TITEL\"]\n",
    "    kuenstler = row[\"KUENSTLER\"]\n",
    "    standort = row[\"STANDORT\"]\n",
    "    lon = row[\"Easting_WGS\"]\n",
    "    lat = row[\"Northing_WGS\"]\n",
    "    \n",
    "    # prepare insert string\n",
    "    insert_string = \"\"\"INSERT INTO gta_tutor.kunst_im_stadtraum (titel, kuenstler, standort, lon, lat)\n",
    "                    VALUES(%s, %s, %s, %s, %s);\"\"\"\n",
    "    # cur.execute() statement\n",
    "    cur.execute(insert_string, (titel, kuenstler, standort, lon, lat))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validate process\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition der Funktion count_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_items(tablename, dbname, port, user, password, host):\n",
    "    \"\"\"count all items in a database \"\"\"\n",
    "    \n",
    "    conn = psycopg2.connect(dbname=dbname, port=port, user=user, password=password, host=host)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"select count(*) from %s\", (AsIs(tablename),))\n",
    "    conn.commit()\n",
    "\n",
    "    results = cur.fetchall()\n",
    "    conn.close()\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8\n",
    "\n",
    "Test your result with the function **count_items**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your output with count_items functions\n",
    "items_in_table = count_items(\"kunst_im_stadtraum\", **db_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether the number of rows in the database corresponds to the rows in our source1 table\n",
    "print(f\"In the database we now have {items_in_table[0][0]} items\")\n",
    "assert items_in_table[0][0] == len(source1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.2: Importing the second csv file\n",
    "\n",
    "This exercise is almost identical to 3.1. You can reuse your code of exercise 3.1. **However, the columns are named differently in the second csv! Make sure to use the correct column names.**\n",
    "\n",
    "Again, make sure to only fill the columns titel, kuenstler, standort, lon and lat, since we will fill the geom column in exercise 4.\n",
    "\n",
    "Use the function **count_items** again to check your result. There should now be 388 rows in your table in the database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Connect and iterate over the rows of source2 to import them\n",
    "# solution\n",
    "conn = psycopg2.connect(**db_credentials)\n",
    "cur = conn.cursor()\n",
    "\n",
    "#loop all rows from csv1\n",
    "for idx, row in source2.iterrows():\n",
    "    \n",
    "    #prepate list of input values\n",
    "    titel = row[\"titel\"]\n",
    "    kuenstler = row[\"kuenstler\"]\n",
    "    standort = row[\"standort\"]\n",
    "    lon = row[\"lon\"]\n",
    "    lat = row[\"lat\"]\n",
    "    \n",
    "    # prepare insert string\n",
    "    insert_string = \"\"\"INSERT INTO gta_tutor.kunst_im_stadtraum (titel, kuenstler, standort, lon, lat)\n",
    "                    VALUES(%s, %s, %s, %s, %s);\"\"\"\n",
    "    # cur.execute() statement\n",
    "    cur.execute(insert_string, (titel, kuenstler, standort, lon, lat))\n",
    "    \n",
    "#validate process\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: count rows with count_items function\n",
    "items_in_table = count_items(\"kunst_im_stadtraum\", **db_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"In the database we now have {items_in_table[0][0]} items\")\n",
    "assert items_in_table[0][0] == 388"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.3: Reading data from the database\n",
    "\n",
    "To check our table and what we have inserted, we can print a few rows from the database, using a simple SQL SELECT statement. When we execute a query with `cur.execute()` and `cur.commit()`, we can retrieve the results with `cur.fetchall()`. \n",
    "\n",
    "### 3.3.1: Add a suitable sql query to the following code, such that the first five rows of the table in the PostgreSQL database are printed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(**db_credentials)\n",
    "cur = conn.cursor()\n",
    "\n",
    "# SOLUTION\n",
    "sql = \"SELECT * from gta_tutor.kunst_im_stadtraum LIMIT 5\"\n",
    "\n",
    "cur.execute(sql)\n",
    "conn.commit()\n",
    "results = cur.fetchall()\n",
    "conn.close()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have realized that we copy and paste the code to initialize and to close connections a lot of times. Since we generally want to avoid repitions when writing code, we will now define a function `read_sql`, which allows to execute any SQL query on the database:\n",
    "\n",
    "Example:\n",
    "```python\n",
    "data = read_sql(sql_string, **db_credentials)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sql(sql, dbname, port, user, password, host ):\n",
    "    \"\"\"execute sql query on database and return results\"\"\"\n",
    "\n",
    "    conn = psycopg2.connect(dbname=dbname, port=port, user=user, password=password, host=host)\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    cur.execute(sql)\n",
    "    conn.commit()\n",
    "\n",
    "    #get results and clean up\n",
    "    results = cur.fetchall()\n",
    "    conn.close()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 Filtering data with SQL via Python:\n",
    "\n",
    "Use the function **read_sql** for the following query: Find all artworks that were created by Franz Fischer (kuenstler = 'Franz Fischer (1900-1980)')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get all art pieces on fountains\n",
    "# SOLUTION\n",
    "sql = \"SELECT titel, kuenstler, standort FROM gta_tutor.kunst_im_stadtraum WHERE kuenstler = 'Franz Fischer (1900-1980)'\"\n",
    "data = read_sql(sql, **db_credentials)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4: Creating a geometry\n",
    "\n",
    "You have loaded the data from both csv files into the PostGIS database. However, the column `geometry` is still empty. In this exercise, we aim to fill this column with `Point` data.\n",
    "\n",
    "### Steps:\n",
    "\n",
    "1. Create a similar function as `read_sql` which can be used to write to the database. Name this function `write_sql`. The function should take an sql query and the database credentials as inputs. It should then execute the query and close the connection.\n",
    "\n",
    "2. Create an SQL string for adding a geometry. Here, we will use the PostGIS function `ST_MakePoint`, and fill it with the values from the already existing columns `lat` and `lon`. The MakePoint statement consists of several components: The core is an *UPDATE* statement, because we want to change the existing column `geometry`.\n",
    "\n",
    "+ Syntax of **Update** statement\n",
    "```SQL\n",
    "UPDATE schema_name.table_name SET column_name = value\n",
    "```\n",
    "\n",
    "Then you need to create a point with *ST_MakePoint* and add it with a coordinate reference system using *ST_SetSRID*. Example:\n",
    "\n",
    "```SQL\n",
    "UPDATE schema_name.table_name SET geometry_column_name = \n",
    "ST_SetSRID(ST_MakePoint(lon_column_name,lat_column_name),4326);\n",
    "```\n",
    "\n",
    "3. Execute the SQL string with your new `write_sql` function.\n",
    "4. Print the first five lines of your table again to check whether the geometry column was added successfully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "def write_sql(sql, dbname, port, user, password, host):\n",
    "    \"\"\"execute sql query on database\"\"\"\n",
    "    conn = psycopg2.connect(dbname=dbname, port=port, user=user, password=password, host=host)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(sql)\n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "geom_sql = \"UPDATE gta_tutor.kunst_im_stadtraum SET geometry = ST_SetSRID(ST_MakePoint(lon,lat),4326);\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "write_sql(geom_sql, **db_credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "read_sql(\"SELECT * from gta_tutor.kunst_im_stadtraum LIMIT 5\", **db_credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5: Spatial queries with PostGIS\n",
    "\n",
    "So far, we have only inserted a geometry, but we have not executed any spatial queries. As seen in the SQL part of the exercise, PostGIS provides many functions for filtering and joining geometric data. Use the function `ST_DWithin` to answer the following query:\n",
    "\n",
    "**Find all artworks, that are less than 1km away from the artwork [Steinvase auf Sockel]**\n",
    "\n",
    "Tips:\n",
    "* [Steinvase auf Sockel] is located at (8.58148801, 47.348233)\n",
    "* The function `ST_DWithin` must be used in a WHERE Statement. Check out the documentation: https://postgis.net/docs/ST_DWithin.html\n",
    "* Careful: We want to know the distance in meters! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION:\n",
    "# We set the argument `use_squeriod` to true, to ensure that the distance in meters is returned.\n",
    "geom_query = \"SELECT * FROM gta_tutor.kunst_im_stadtraum WHERE ST_DWithin(geometry, 'SRID=4326;POINT(8.58148801 47.348233)', 1000, true)\"\n",
    "results = read_sql(geom_query, **db_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(results) == 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6: Simplified database access with pandas\n",
    "\n",
    "So far, we have used psycopg2 functions to get to know the typical workflow of database access. However, there are of course Python packages that have already integrated database access and take over the task of dealing with the connection object. Pandas offers this functionality with the [to_sql](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_sql.html) and [read_sql](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_sql.html) functions, and Geopandas has the corresponding functions `to_postgis` and `read_postgis`. For further work with databases in your project, you can use these functions to query data from the database or to add / update tables. **As an exercise, have a look at the documentation of `read_postgis` and use it to retrieve the data (first 10 rows) including the geometry from our PostGIS database.**\n",
    "\n",
    "Tip: Pandas requires a connection engine created with sqlalchemy instead of psycopg2. Use the following line to set up the engine:\n",
    "\n",
    "Tip2: If you receive the error `TypeError: __init__() got multiple values for argument 'schema'` you need to update pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import geopandas as gpd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_string = f\"postgresql://{db_credentials['user']}:{db_credentials['password']}@{db_credentials['host']}:{db_credentials['port']}/{db_credentials['dbname']}\"        \n",
    "print(\"Create string for sqlalchemy engine:\", create_string)\n",
    "engine = create_engine(create_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use gpd.read_postgis to retrieve the first 10 rows including the geometry\n",
    "# SOLUTION:\n",
    "test = gpd.read_postgis(\"SELECT * FROM kunst_im_stadtraum LIMIT 10\", con=engine.connect(), geom_col=\"geometry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert that the geometry is read correctly\n",
    "assert np.isclose(test.geometry.iloc[0].x, 8.58148801000993), \"wrong point, check your geometry and rows\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
